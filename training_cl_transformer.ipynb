{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0dffac96-2bb2-4e56-ab1f-ccbd28c366c9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6b5180078d43481bb8b78cf2089a0596",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(HTML(value='<center> <img\\nsrc=https://huggingface.co/front/assets/huggingface_logo-noborder.sv…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from transformers import PegasusTokenizer, PegasusForConditionalGeneration, AutoModel\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from sklearn.model_selection import train_test_split\n",
    "import torch\n",
    "from tqdm import tqdm\n",
    "import os\n",
    "from huggingface_hub import login\n",
    "import datasets\n",
    "login()\n",
    "from nltk.tokenize import sent_tokenize\n",
    "import nltk\n",
    "nltk.download('punkt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "dcac641a-0973-45b3-ace3-fc50d9fa05fe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "412c7e4bc370419489c13c4eb32b2342",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading readme:   0%|          | 0.00/307 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2281db17d7fb444e91596a38a088a6a6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading data:   0%|          | 0.00/297k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "45d5950969214107be4f8f247e71a604",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating train split:   0%|          | 0/173 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "sent_essays = datasets.load_dataset(\"AnkushRaut216/test_essays\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9cdcf96d-1170-4e2f-af08-4a6c2ba512f1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4588"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sent_essays_pd = sent_essays['train'].to_pandas()\n",
    "sentences = sum([sent_tokenize(sent_essays_pd['text'][a]) for a in range(len(sent_essays_pd))], [])\n",
    "len(sentences)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39ea72bc-23ad-4509-bc09-4ac514f5e716",
   "metadata": {},
   "source": [
    "## Generating paraphrases 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "23fb85db-dc68-4741-9ea7-269b605e0fd3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/projects/anra7539/software/anaconda/envs/kgenv/lib/python3.11/site-packages/torch/_utils.py:831: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n",
      "  return self.fget.__get__(instance, owner)()\n",
      "Some weights of PegasusForConditionalGeneration were not initialized from the model checkpoint at tuner007/pegasus_paraphrase and are newly initialized: ['model.decoder.embed_positions.weight', 'model.encoder.embed_positions.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "tokenizer = PegasusTokenizer.from_pretrained(\"tuner007/pegasus_paraphrase\")\n",
    "model = PegasusForConditionalGeneration.from_pretrained(\"tuner007/pegasus_paraphrase\",\n",
    "                                                    cache_dir = '/scratch/alpine/anra7539').to(\"cuda\")\n",
    "\n",
    "\n",
    "def paraphrase_text(text, paraphrase_limit = 30):\n",
    "  input_ids = tokenizer.encode(text, return_tensors=\"pt\", truncation=True).to(\"cuda\")\n",
    "  paraphrase_ids = model.generate(input_ids, max_length=paraphrase_limit, min_length=5, num_beams=2,\n",
    "                                length_penalty=1.0, early_stopping=True)\n",
    "  paraphrase = tokenizer.decode(paraphrase_ids[0], skip_special_tokens=True)\n",
    "\n",
    "  return paraphrase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "37aac1d9-b9b2-4457-9260-3ac4c4da4a02",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4588/4588 [18:11<00:00,  4.21it/s]\n"
     ]
    }
   ],
   "source": [
    "paraphrases = []\n",
    "for sentence in tqdm(sentences):\n",
    "    paraphrases.append(paraphrase_text(sentence))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8439930f-325a-49ab-8745-dd6611227f7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "sentence_df = pd.DataFrame({\"original_sentence\":sentences, \"paraphrases\":paraphrases})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "156ac774-7ea7-4426-905c-54245cef0dd6",
   "metadata": {},
   "source": [
    "## Generating paraphrases 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ca6e22db-1f7d-4326-a287-af968337e2ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of PegasusForConditionalGeneration were not initialized from the model checkpoint at tuner007/pegasus_paraphrase and are newly initialized: ['model.decoder.embed_positions.weight', 'model.encoder.embed_positions.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "tokenizer = PegasusTokenizer.from_pretrained(\"tuner007/pegasus_paraphrase\")\n",
    "model = PegasusForConditionalGeneration.from_pretrained(\"tuner007/pegasus_paraphrase\",\n",
    "                                                    cache_dir = '/scratch/alpine/anra7539').to(\"cuda\")\n",
    "\n",
    "\n",
    "def paraphrase_text2(text, paraphrase_limit = 30):\n",
    "  input_ids = tokenizer.encode(text, return_tensors=\"pt\", truncation=True).to(\"cuda\")\n",
    "  paraphrase_ids = model.generate(input_ids, max_length=paraphrase_limit, min_length=5, num_beams=4,\n",
    "                                  do_sample = True, length_penalty=1.0, early_stopping=True)\n",
    "  paraphrase = tokenizer.decode(paraphrase_ids[0], skip_special_tokens=True)\n",
    "\n",
    "  return paraphrase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6be7c03c-af0d-4784-b691-88b368474ca5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4588/4588 [20:32<00:00,  3.72it/s]\n"
     ]
    }
   ],
   "source": [
    "paraphrases2 = []\n",
    "for sentence in tqdm(sentences):\n",
    "    paraphrases2.append(paraphrase_text2(sentence))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e5dfd6a4-7fa9-436b-9adc-84cbbee3eedf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "22df5307acd04b4a946d724dda69e3d2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Uploading the dataset shards:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bb75716e186b4357b6e9b93d9bd541ad",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Creating parquet from Arrow format:   0%|          | 0/10 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "CommitInfo(commit_url='https://huggingface.co/datasets/AnkushRaut216/llm_generated_sentences_data_final/commit/11c45d15c5159a93a695e4485e09754e999c9100', commit_message='Upload dataset', commit_description='', oid='11c45d15c5159a93a695e4485e09754e999c9100', pr_url=None, pr_revision=None, pr_num=None)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentence_df2 = pd.DataFrame({\"original_sentence\":sentences, \"paraphrases\":paraphrases2})\n",
    "final_df = pd.concat([sentence_df, sentence_df2], ignore_index = True)\n",
    "datasets.Dataset.from_pandas(final_df).push_to_hub(\"AnkushRaut216/llm_generated_sentences_data_final\", private = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2bcdc486-535f-4e44-9053-d6a842e276d6",
   "metadata": {},
   "source": [
    "### Contrastive learning df creation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e259661d-e6b4-4b93-a236-db5bb807ff44",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0a654426826847c4a62875ca693755c1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading readme:   0%|          | 0.00/327 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "75eae2a656a843d59e1b90d6a33be291",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading data:   0%|          | 0.00/1.05M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8982a947ef5f4b679908ed85e416a237",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating train split:   0%|          | 0/9176 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "cl_data = datasets.load_dataset(\"AnkushRaut216/llm_generated_sentences_data_final\")\n",
    "cl_data_pd = cl_data['train'].to_pandas()\n",
    "\n",
    "cl_data_pd['label'] = [1]*len(cl_data_pd)\n",
    "\n",
    "unique_sentences = cl_data_pd.iloc[:int(len(cl_data_pd)/2),:].original_sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7fadcbc9-7cd0-496a-9d96-01d849988b72",
   "metadata": {},
   "outputs": [],
   "source": [
    "cl_data_pd.rename(columns = {'paraphrases':'sentence2'}, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bd0e723b-4af8-4d6b-bf86-c4ece6de1b3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "negative_sentences1 = []\n",
    "negative_sentences2 = []\n",
    "negative_sentences3 = []\n",
    "for sent in unique_sentences:\n",
    "    negative_sentences1.append(np.random.choice(unique_sentences[unique_sentences!= sent]))\n",
    "    negative_sentences2.append(np.random.choice(unique_sentences[unique_sentences!= sent]))\n",
    "    negative_sentences3.append(np.random.choice(unique_sentences[unique_sentences!= sent]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "06958e64-28c6-4f23-9e59-2259d3662925",
   "metadata": {},
   "outputs": [],
   "source": [
    "negative_df1 = pd.DataFrame({'original_sentence':unique_sentences, 'sentence2':negative_sentences1})\n",
    "negative_df2 = pd.DataFrame({'original_sentence':unique_sentences, 'sentence2':negative_sentences2})\n",
    "negative_df3 = pd.DataFrame({'original_sentence':unique_sentences, 'sentence2':negative_sentences3})\n",
    "\n",
    "negative_df = pd.concat([negative_df1, negative_df2, negative_df3], ignore_index = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "fe34d5d1-ca2f-4890-8457-dfe2a58bb56d",
   "metadata": {},
   "outputs": [],
   "source": [
    "negative_df['label'] = [0]*len(negative_df)\n",
    "full_cl_df = pd.concat([cl_data_pd, negative_df], ignore_index = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "fc1a7ba6-be1d-4166-8bb3-937a2f454c91",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(22940, 3)\n",
      "(20686, 3)\n"
     ]
    }
   ],
   "source": [
    "print(full_cl_df.shape)\n",
    "full_cl_df.drop_duplicates(inplace = True)\n",
    "print(full_cl_df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "00754707-c604-4ce8-a81d-6f852fdc61d4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "label\n",
       "0    13759\n",
       "1     6927\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "full_cl_df.label.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9cde8e0a-0b88-49e7-a436-58ca92d0d4d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "full_cl_df.reset_index(drop = True, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "77f0a049-7888-40a1-b54e-e0411735c687",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bd133be2974542598bc88798933ef1c5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Uploading the dataset shards:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e54e1e5414cf4a35b08c97cc9aaa8986",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Creating parquet from Arrow format:   0%|          | 0/21 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "388d9311b5024c698b6d32ea60a42d47",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "README.md:   0%|          | 0.00/359 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fa314b32067044eeb2250c2f58bf8333",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading readme:   0%|          | 0.00/359 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1a746d5b1b0e4e3ba350b24c07066d52",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading data:   0%|          | 0.00/2.63M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "46cadf5ea42b4feda5512b0cf488147a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating train split:   0%|          | 0/20686 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "datasets.Dataset.from_pandas(full_cl_df).push_to_hub(\"AnkushRaut216/full_cl_data\", private = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "516ad6a7-65f0-4979-af73-6f44701a5c40",
   "metadata": {},
   "source": [
    "## Contrastive Learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "334e3051-cce0-4312-88c5-d87004b7efd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "full_cl_df = datasets.load_dataset(\"AnkushRaut216/full_cl_data\")['train'].to_pandas()\n",
    "train, val = train_test_split(full_cl_df, test_size = 0.25, stratify = full_cl_df.label, random_state = 2024)\n",
    "train.reset_index(drop = True, inplace = True)\n",
    "val.reset_index(drop = True, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bd38a940-9103-4259-97aa-4b36da7ab564",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/48500 [00:00<?, ?it/s]"
     ]
    }
   ],
   "source": [
    "model = SentenceTransformer('sentence-transformers/all-MiniLM-L6-v2', cache_folder = \"/scratch/alpine/anra7539\").to(\"cuda\")\n",
    "\n",
    "class ContrastiveLoss(torch.nn.Module):\n",
    "    def __init__(self, margin=1.0):\n",
    "        super(ContrastiveLoss, self).__init__()\n",
    "        self.margin = margin\n",
    "\n",
    "    def forward(self, embeddings1, embeddings2, labels):\n",
    "        euclidean_distance = torch.nn.functional.pairwise_distance(embeddings1, embeddings2, keepdim=True)\n",
    "        loss_contrastive = torch.mean((1-labels) * torch.pow(euclidean_distance, 2) +\n",
    "                                      (labels) * torch.pow(torch.clamp(self.margin - euclidean_distance, min=0.0), 2))\n",
    "        return loss_contrastive\n",
    "\n",
    "criterion = ContrastiveLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-5)\n",
    "train_dataset = [[train.original_sentence[i], train.sentence2[i], train.label[i]] for i in range(len(train))]\n",
    "val_dataset = [[val.original_sentence[i], val.sentence2[i], val.label[i]] for i in range(len(val))]\n",
    "\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=16, shuffle=True)\n",
    "val_dataloader = DataLoader(val_dataset, batch_size=16, shuffle=True)\n",
    "\n",
    "early_stopping_rounds = 5  \n",
    "best_validation_loss = float('inf')\n",
    "no_improvement_count = 0\n",
    "\n",
    "num_epochs = 50\n",
    "num_training_steps = num_epochs * len(train_dataloader)\n",
    "progress_bar = tqdm(range(num_training_steps))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cc321a67-5d6a-499d-abcf-d8de52cf5f67",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|█▉        | 9699/48500 [02:41<08:17, 77.93it/s]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping after 10 epochs with no improvement.\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(num_epochs):\n",
    "    for batch in train_dataloader:\n",
    "        sentences1, sentences2, labels = batch\n",
    "\n",
    "        embeddings1 = torch.tensor(model.encode(sentences1), requires_grad = True).to(\"cuda\")\n",
    "        embeddings2 = torch.tensor(model.encode(sentences2), requires_grad = True).to(\"cuda\")\n",
    "        labels = labels.to(\"cuda\")\n",
    "\n",
    "        loss = criterion(embeddings1, embeddings2, labels.float())\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        progress_bar.update(1)\n",
    "\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        val_loss = 0\n",
    "        for batch in val_dataloader:\n",
    "            sentences1, sentences2, labels = batch\n",
    "\n",
    "            embeddings1 = torch.tensor(model.encode(sentences1), requires_grad = False).to(\"cuda\")\n",
    "            embeddings2 = torch.tensor(model.encode(sentences2), requires_grad = False).to(\"cuda\")\n",
    "            labels = labels.to(\"cuda\")\n",
    "\n",
    "            val_loss+=criterion(embeddings1, embeddings2, labels.float())\n",
    "            \n",
    "        if val_loss < best_validation_loss:\n",
    "            best_validation_loss = val_loss\n",
    "            no_improvement_count = 0\n",
    "            \n",
    "            model.save('/scratch/alpine/anra7539/contrastive_learning_model/best_model')\n",
    "        else:\n",
    "            no_improvement_count += 1\n",
    "\n",
    "\n",
    "        if no_improvement_count >= early_stopping_rounds:\n",
    "            print(f'Early stopping after {epoch+1} epochs with no improvement.')\n",
    "            break\n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcad5a15-ff9f-4766-8694-2c5bf1d5d51d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
