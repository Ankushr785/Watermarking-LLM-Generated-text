{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c9f86997-f493-4b0e-9e96-9d93accd675b",
   "metadata": {},
   "source": [
    "## In this notebook, an LLM detection classification pipeline has been developed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7ca95ead-1a85-4089-a8dc-25b60dd6b02d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5a64de2993bf4c05a6aca124bd7af636",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(HTML(value='<center> <img\\nsrc=https://huggingface.co/front/assets/huggingface_logo-noborder.sv…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /home/anra7539/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "from tqdm import tqdm\n",
    "from sklearn.metrics import roc_auc_score, f1_score, confusion_matrix\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "from transformers import AutoModelForSequenceClassification, AutoTokenizer, AutoConfig\n",
    "from torch.optim import AdamW\n",
    "from transformers import get_scheduler\n",
    "from sklearn.model_selection import train_test_split\n",
    "import datasets\n",
    "from huggingface_hub import login\n",
    "from sklearn import metrics\n",
    "import ast\n",
    "import nltk\n",
    "nltk.download('punkt')\n",
    "\n",
    "login()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "adf1d615-12e1-44b8-af11-f3f29f3ed232",
   "metadata": {},
   "source": [
    "### Importing datasets and preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5893a1d7-8c9b-4af8-a356-3d45ce4ea48c",
   "metadata": {},
   "outputs": [],
   "source": [
    "preliminary_data = datasets.load_dataset(\"AnkushRaut216/llm_generated_text\")\n",
    "argugpt = datasets.load_dataset(\"AnkushRaut216/argugpt_data\")\n",
    "\n",
    "# Converting huggingface datasets to pandas df for better processing\n",
    "preliminary_data_pd = preliminary_data['train'].to_pandas()\n",
    "argugpt_pd = argugpt['train'].to_pandas()\n",
    "\n",
    "# Adding label to the argugpt data\n",
    "argugpt_pd.drop_duplicates(subset = ['text'], inplace = True)\n",
    "argugpt_pd['generated'] = [1]*len(argugpt_pd)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a286b1f-122b-4565-a521-3112b636740d",
   "metadata": {},
   "source": [
    "### Defining the classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "32237d53-45f6-47fe-b3f5-77c1e98262a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = \"distilbert/distilbert-base-uncased-finetuned-sst-2-english\"\n",
    "\n",
    "device = \"cuda\"\n",
    "model = AutoModelForSequenceClassification.from_pretrained(model_name,\n",
    "                                             device_map = device,\n",
    "                                             cache_dir='/scratch/alpine/anra7539').to(device)\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name, truncation = True)\n",
    "\n",
    "config = AutoConfig.from_pretrained(f\"distilbert/distilbert-base-uncased-finetuned-sst-2-english\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "fc5dfaad-c3ad-4f94-beaf-45737d101209",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_essays = pd.concat([preliminary_data_pd[['text', 'generated']], \n",
    "                          argugpt_pd[['text', 'generated']]], ignore_index = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "19b05092-7211-4c0c-a838-900f88ee0fff",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_val, test = train_test_split(train_essays, test_size = 0.1, \n",
    "                              stratify = train_essays['generated'],\n",
    "                              random_state = 2024)\n",
    "\n",
    "train, val = train_test_split(train_val, test_size = 0.25, \n",
    "                              stratify = train_val['generated'],\n",
    "                             random_state = 2024)\n",
    "\n",
    "train.reset_index(drop = True, inplace = True)\n",
    "test.reset_index(drop = True, inplace = True)\n",
    "val.reset_index(drop = True, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a11379e1-3d1b-4921-a2e3-66563a0fe6a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# login()\n",
    "# datasets.Dataset.from_pandas(test).push_to_hub(\"AnkushRaut216/test_essays\", private = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "53db9394-4fbd-4cd8-97e3-de3eb3a126c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenized_inputs_train = tokenizer(list(train['text']), padding=True, truncation=True, \n",
    "                             return_tensors=\"pt\")\n",
    "labels_train = torch.tensor(list(train['generated']))\n",
    "\n",
    "tokenized_inputs_val = tokenizer(list(val['text']), padding=True, truncation=True, \n",
    "                             return_tensors=\"pt\")\n",
    "labels_val = torch.tensor(list(val['generated']))\n",
    "\n",
    "dataset_train = TensorDataset(tokenized_inputs_train[\"input_ids\"], \n",
    "                        tokenized_inputs_train[\"attention_mask\"], labels_train)\n",
    "dataloader = DataLoader(dataset_train, batch_size=32, shuffle=True)\n",
    "\n",
    "dataset_val = TensorDataset(tokenized_inputs_val[\"input_ids\"], \n",
    "                        tokenized_inputs_val[\"attention_mask\"], labels_val)\n",
    "val_dataloader = DataLoader(dataset_val, batch_size=32, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "96557fbe-6c49-4822-a98d-2182ecd632c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/370 [00:00<?, ?it/s]"
     ]
    }
   ],
   "source": [
    "num_epochs = 10\n",
    "\n",
    "optimizer = AdamW(model.parameters(), lr=1e-5)\n",
    "num_training_steps = num_epochs * len(dataloader)\n",
    "lr_scheduler = get_scheduler(\n",
    "    name=\"linear\", optimizer=optimizer, num_warmup_steps=0, \n",
    "    num_training_steps=num_training_steps\n",
    ")\n",
    "\n",
    "early_stopping_rounds = 3  \n",
    "best_validation_loss = float('inf')\n",
    "no_improvement_count = 0\n",
    "\n",
    "progress_bar = tqdm(range(num_training_steps))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "36fb31b4-882e-4b71-bc7e-54d531453884",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 70%|███████   | 259/370 [01:41<00:38,  2.92it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping after 7 epochs with no improvement.\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    for i,batch in enumerate(dataloader):\n",
    "        input_ids, attention_mask, label = batch\n",
    "        input_ids, attention_mask, label = input_ids.to(\"cuda\"), attention_mask.to(\"cuda\"), label.to(\"cuda\") \n",
    "\n",
    "        outputs = model(input_ids, attention_mask=attention_mask, labels=label)\n",
    "        loss = outputs.loss\n",
    "\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        lr_scheduler.step()\n",
    "        optimizer.zero_grad()\n",
    "        progress_bar.update(1)\n",
    "        \n",
    "    # model.save_pretrained('scratch/alpine/anra7539/llm_detector_v2/best_model')\n",
    "    # tokenizer.save_pretrained('scratch/alpine/anra7539/llm_detector_v2/best_model')\n",
    "    \n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        val_loss = 0\n",
    "        for batch in val_dataloader:\n",
    "            input_ids, attention_mask, label = batch\n",
    "            input_ids, attention_mask, label = input_ids.to(\"cuda\"), attention_mask.to(\"cuda\"), label.to(\"cuda\") \n",
    "\n",
    "            outputs = model(input_ids, attention_mask=attention_mask, labels=label)\n",
    "            val_loss += outputs.loss.item()\n",
    "            \n",
    "        if val_loss < best_validation_loss:\n",
    "            best_validation_loss = val_loss\n",
    "            no_improvement_count = 0\n",
    "            \n",
    "            model.save_pretrained('/scratch/alpine/anra7539/llm_detector_v7/best_model')\n",
    "            tokenizer.save_pretrained('/scratch/alpine/anra7539/llm_detector_v7/best_model')\n",
    "        else:\n",
    "            no_improvement_count += 1\n",
    "\n",
    "\n",
    "        if no_improvement_count >= early_stopping_rounds:\n",
    "            print(f'Early stopping after {epoch+1} epochs with no improvement.')\n",
    "            break\n",
    "            \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8d7613e4-7fc6-4c5d-affa-49ef52681bd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "load_path = \"/scratch/alpine/anra7539/llm_detector_v7/best_model\"\n",
    "\n",
    "model = AutoModelForSequenceClassification.from_pretrained(load_path, device_map = device).to(device)\n",
    "tokenizer = AutoTokenizer.from_pretrained(load_path, truncation = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b5896a4c-4fdc-4cfa-9846-ed553a6f0557",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "predictions_train = []\n",
    "predictions_val = []\n",
    "predictions_test = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for text in train.text:\n",
    "        \n",
    "        input_ids = tokenizer(text, \n",
    "                      padding=True, \n",
    "                      truncation=True,  \n",
    "                      return_tensors='pt')[\"input_ids\"].to(\"cuda\")\n",
    "        \n",
    "        outputs = model(input_ids)\n",
    "        predictions_train.append(torch.nn.functional.sigmoid(outputs.logits))\n",
    "        \n",
    "    for text in val.text:\n",
    "        \n",
    "        input_ids = tokenizer(text, \n",
    "                      padding=True, \n",
    "                      truncation=True,  \n",
    "                      return_tensors='pt')[\"input_ids\"].to(\"cuda\")\n",
    "        \n",
    "        outputs = model(input_ids)\n",
    "        predictions_val.append(torch.nn.functional.sigmoid(outputs.logits))\n",
    "        \n",
    "    for text in test.text:\n",
    "        \n",
    "        input_ids = tokenizer(text, \n",
    "                      padding=True, \n",
    "                      truncation=True,  \n",
    "                      return_tensors='pt')[\"input_ids\"].to(\"cuda\")\n",
    "        \n",
    "        outputs = model(input_ids)\n",
    "        predictions_test.append(torch.nn.functional.sigmoid(outputs.logits))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5d78999e-9724-4984-9920-b32e812293df",
   "metadata": {},
   "outputs": [],
   "source": [
    "preds_train = [np.array(a.to(\"cpu\"))[0][1] for a in predictions_train]\n",
    "preds_val = [np.array(a.to(\"cpu\"))[0][1] for a in predictions_val]\n",
    "preds_test = [np.array(a.to(\"cpu\"))[0][1] for a in predictions_test]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ccc7197e-ed77-4622-ad00-51a804b5c28b",
   "metadata": {},
   "outputs": [],
   "source": [
    "fpr, tpr, _ = metrics.roc_curve(train['generated'],  preds_train)\n",
    "auc = metrics.roc_auc_score(train['generated'], preds_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ba4858bb-5bcf-43bb-b286-c677ae560a60",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Selecting threshold by averaging the thresholds that give a tpr above 0.9 and an fpr below 0.1 on training data\n",
    "\n",
    "threshold_df = pd.DataFrame({\"threshold\":_, \"fpr\":fpr, \"tpr\":tpr})\n",
    "threshold = np.mean(threshold_df[(threshold_df.tpr>0.8) & (threshold_df.fpr<0.2)].threshold)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "f5298922-fe84-4ee8-9616-4875908173c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions_train_dis = np.where(preds_train>=threshold,1,0)\n",
    "predictions_val_dis = np.where(preds_val>=threshold,1,0)\n",
    "predictions_test_dis = np.where(preds_test>=threshold,1,0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "e1002fd9-3d46-493d-8618-6637b5349ae4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test accuracy = 0.9884393063583815\n"
     ]
    }
   ],
   "source": [
    "print(f\"Test accuracy = {metrics.accuracy_score(test.generated, predictions_test_dis)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "e64eee6a-141f-40bb-b1b1-f79be2d37e7e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      1.00      0.99       138\n",
      "           1       1.00      0.94      0.97        35\n",
      "\n",
      "    accuracy                           0.99       173\n",
      "   macro avg       0.99      0.97      0.98       173\n",
      "weighted avg       0.99      0.99      0.99       173\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(metrics.classification_report(test.generated, predictions_test_dis))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a806c20-ac1f-45ab-a4a8-8d1f67d230fe",
   "metadata": {},
   "source": [
    "## Testing watermarked essays"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "860525d7-98cf-4617-8d89-471ad5ea2caa",
   "metadata": {},
   "outputs": [],
   "source": [
    "watermarked_essays = pd.read_csv('all_watermarked_essays.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "e276291c-5f0a-47e3-81a2-24ec5100ff40",
   "metadata": {},
   "outputs": [],
   "source": [
    "watermarked_essays['text'] = [\" \".join(ast.literal_eval(a)) for a in watermarked_essays.text]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "d0de40e1-6e6a-4c06-9a51-1cf2456eb277",
   "metadata": {},
   "outputs": [],
   "source": [
    "watermarked_essays['original_text'] = test['text']\n",
    "watermarked_essays['generated'] = test['generated']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "804ba44d-92ef-424e-83dd-133283a31348",
   "metadata": {},
   "outputs": [],
   "source": [
    "watermarked_essays.text = np.where(watermarked_essays.generated == 1, watermarked_essays.text,\n",
    "                                   watermarked_essays.original_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "7c0fd27b-a37b-44d6-ab19-bbd37d7fcc3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions_on_watermarked = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for text in watermarked_essays.text:\n",
    "        \n",
    "        input_ids = tokenizer(text, \n",
    "                      padding=True, \n",
    "                      truncation=True,  \n",
    "                      return_tensors='pt')[\"input_ids\"].to(\"cuda\")\n",
    "        \n",
    "        outputs = model(input_ids)\n",
    "        predictions_on_watermarked.append(torch.nn.functional.sigmoid(outputs.logits))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "e9952047-a5aa-49ea-9fee-8e3d8721385b",
   "metadata": {},
   "outputs": [],
   "source": [
    "preds_watermarked = [np.array(a.to(\"cpu\"))[0][1] for a in predictions_on_watermarked]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "bd10917f-e8ab-4cd4-bf00-a1616d252470",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions_watermarked_dis = np.where(preds_watermarked>=threshold,1,0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "4ba52680-5c7f-4c1a-b4fc-48f75677cd2f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on data with watermarked_text = 0.9248554913294798\n"
     ]
    }
   ],
   "source": [
    "print(f\"Accuracy on data with watermarked_text = {metrics.accuracy_score(watermarked_essays.generated, predictions_watermarked_dis)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "e39c32ae-cb2d-4fd1-9627-525bdb78ed85",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      1.00      0.96       138\n",
      "           1       1.00      0.63      0.77        35\n",
      "\n",
      "    accuracy                           0.92       173\n",
      "   macro avg       0.96      0.81      0.86       173\n",
      "weighted avg       0.93      0.92      0.92       173\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(metrics.classification_report(watermarked_essays.generated, predictions_watermarked_dis))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af56bada-4738-456a-b4da-f6c2abfaaa3c",
   "metadata": {},
   "source": [
    "The recall for non-AI generated essays stays the same."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "76012558-7189-4d2f-b5fc-8f3cb6c27bf1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average number of sentences in watermarked essays = 70.62857142857143\n",
      "Average number of sentences in original AI-generated essays = 17.771428571428572\n"
     ]
    }
   ],
   "source": [
    "def count_sentences(text):\n",
    "    sentences = nltk.sent_tokenize(text)\n",
    "    return len(sentences)\n",
    "\n",
    "print(f\"Average number of sentences in watermarked essays = {np.mean([count_sentences(text) for text in watermarked_essays[watermarked_essays.generated == 1].text])}\")\n",
    "print(f\"Average number of sentences in original AI-generated essays = {np.mean([count_sentences(text) for text in test[test.generated == 1].text])}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "36d72e01-3c6d-4049-940d-3a7ba6a49fcc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Standard deviation of number of sentences in watermarked essays = 89.88725818308994\n",
      "Standard deviation of number of sentences in original AI-generated essays = 14.57803771683519\n"
     ]
    }
   ],
   "source": [
    "print(f\"Standard deviation of number of sentences in watermarked essays = {np.std([count_sentences(text) for text in watermarked_essays[watermarked_essays.generated == 1].text])}\")\n",
    "print(f\"Standard deviation of number of sentences in original AI-generated essays = {np.std([count_sentences(text) for text in test[test.generated == 1].text])}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2924884-ca81-48b0-a6db-ca501c16bd6a",
   "metadata": {},
   "source": [
    "### Testing watermarked essays v2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "fdaa7a44-b1f4-40a4-928b-8740659f2103",
   "metadata": {},
   "outputs": [],
   "source": [
    "watermarked_essays = pd.read_csv('all_watermarked_essays_v2.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "af2cbafe-5f39-43db-99ce-81a411130c30",
   "metadata": {},
   "outputs": [],
   "source": [
    "watermarked_essays['text'] = [\" \".join(ast.literal_eval(a)) for a in watermarked_essays.text]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "f47503c1-d4e7-44b0-8592-9b03af80b4b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "watermarked_essays['original_text'] = test['text']\n",
    "watermarked_essays['generated'] = test['generated']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "c2933c4c-d070-4a45-8b0f-e79cb4aa6b88",
   "metadata": {},
   "outputs": [],
   "source": [
    "watermarked_essays.text = np.where(watermarked_essays.generated == 1, watermarked_essays.text,\n",
    "                                   watermarked_essays.original_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "7daa596c-c210-4ddd-a159-ca3645a9fc04",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions_on_watermarked = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for text in watermarked_essays.text:\n",
    "        \n",
    "        input_ids = tokenizer(text, \n",
    "                      padding=True, \n",
    "                      truncation=True,  \n",
    "                      return_tensors='pt')[\"input_ids\"].to(\"cuda\")\n",
    "        \n",
    "        outputs = model(input_ids)\n",
    "        predictions_on_watermarked.append(torch.nn.functional.sigmoid(outputs.logits))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "3b4c9ce7-de53-4f77-9a2e-d4878dee55a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "preds_watermarked = [np.array(a.to(\"cpu\"))[0][1] for a in predictions_on_watermarked]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "030dc48b-b973-4c71-89f8-42896e80e433",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions_watermarked_dis = np.where(preds_watermarked>=threshold,1,0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "c185d78d-9463-4e5b-973d-cef56ad6abfd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on data with watermarked_text = 0.9595375722543352\n"
     ]
    }
   ],
   "source": [
    "print(f\"Accuracy on data with watermarked_text = {metrics.accuracy_score(watermarked_essays.generated, predictions_watermarked_dis)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "3128557b-f187-4b05-ab70-b3383c462673",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      1.00      0.98       138\n",
      "           1       1.00      0.80      0.89        35\n",
      "\n",
      "    accuracy                           0.96       173\n",
      "   macro avg       0.98      0.90      0.93       173\n",
      "weighted avg       0.96      0.96      0.96       173\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(metrics.classification_report(watermarked_essays.generated, predictions_watermarked_dis))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "bce5a42d-948e-47df-b636-085e21ec4066",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average number of sentences in watermarked essays = 23.02857142857143\n",
      "Average number of sentences in original AI-generated essays = 17.771428571428572\n"
     ]
    }
   ],
   "source": [
    "print(f\"Average number of sentences in watermarked essays = {np.mean([count_sentences(text) for text in watermarked_essays[watermarked_essays.generated == 1].text])}\")\n",
    "print(f\"Average number of sentences in original AI-generated essays = {np.mean([count_sentences(text) for text in test[test.generated == 1].text])}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "6d7d2186-7a51-4180-a7a8-234ed46f0378",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Standard deviation of number of sentences in watermarked essays = 13.824379529937502\n",
      "Standard deviation of number of sentences in original AI-generated essays = 14.57803771683519\n"
     ]
    }
   ],
   "source": [
    "print(f\"Standard deviation of number of sentences in watermarked essays = {np.std([count_sentences(text) for text in watermarked_essays[watermarked_essays.generated == 1].text])}\")\n",
    "print(f\"Standard deviation of number of sentences in original AI-generated essays = {np.std([count_sentences(text) for text in test[test.generated == 1].text])}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6859e468-c031-4f70-b5e0-a2b4017813e8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
